# -*- coding: utf-8 -*-
"""Pneumonia_predict_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ma3X4Mugg_t9Hv_O7M1CTsKzevny3BAB
"""

import os
import cv2
import numpy as np
from keras import layers
from keras import models
from keras.models import Sequential
from keras import optimizers
from keras.optimizers import Adam, RMSprop
from keras.utils.np_utils import to_categorical
from keras.layers import  Conv2D,MaxPooling2D,Activation,Flatten,Dense
from keras.applications import VGG16
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator,image,load_img
import matplotlib.pyplot as plt


# Number of images for training
print('total Normal train images: ', len(os.listdir('/content/drive/My Drive/Xray/train/NORMAL')))
print('total Penumonia train images: ', len(os.listdir('/content/drive/My Drive/Xray/train/PNEUMONIA')))

# Number of images for validation
print('total Normal validation images: ', len(os.listdir('/content/drive/My Drive/Xray/val/NORMAL')))
print('total Penumonia validation images: ', len(os.listdir('/content/drive/My Drive/Xray/val/PNEUMONIA')))

# Number of images for testing
print('total Normal test images: ', len(os.listdir('/content/drive/My Drive/Xray/test/NORMAL')))
print('total Pneumonia test images: ', len(os.listdir('/content/drive/My Drive/Xray/test/PNEUMONIA')))

# setting the paths for train, test and val folders
base_dir = '/content/drive/My Drive/Xray'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'val')
test_dir = os.path.join(base_dir, 'test')

# Without Data augmentation

# All images will be rescaled by 1./255 so that the pixel values will be in the range of (0, 1)
train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

# Resizing the image to (150, 150)
# Generating batches of image data from training , testing and validation images 
# For class_mode we select binary because we only have two classes to perdict: Normal or Pneumonia

# Generating images for training
train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(150, 150),
        batch_size=20,
        class_mode='binary')

# Generating images for testing
test_generator = test_datagen.flow_from_directory(
        test_dir,
        target_size=(150, 150),
        batch_size=20,
        class_mode='binary')

# Generating images for validation
validation_generator = test_datagen.flow_from_directory(
        validation_dir,
        target_size=(150, 150),
        batch_size=20,
        class_mode='binary')


# Convolutional model 
model = models.Sequential()
model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(256, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(512, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))

# Model summary
print(model.summary())

# Compiling the model
model.compile(loss='binary_crossentropy',
              optimizer=optimizers.RMSprop(lr=1e-4),
              metrics=['acc'])

# Building the model
history = model.fit_generator(
      train_generator,
      steps_per_epoch=100,
      epochs=30,
      validation_data=validation_generator)

#Saving the model  
# model.save('cnn_model.h5')

# Accuracy on test data when trained with non-augmented training data
test_loss, test_accuracy = model.evaluate_generator(test_generator, steps=50) 
print(test_accuracy)

# plotting accuracy and loss graphs for training and validation
acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

'''
            With Data Augmentation
'''
# We only augment the training data

# Rotating 40 degrees
# width and height shift by 0.2
# Zoom in by 0.2
# Flipping the image
train_datagen = ImageDataGenerator(
      rescale=1./255,
      rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(150, 150),
        batch_size=20,
        class_mode='binary')
test_generator = test_datagen.flow_from_directory(
        test_dir,
        target_size=(150, 150),
        batch_size=20,
        class_mode='binary')
validation_generator = test_datagen.flow_from_directory(
        validation_dir,
        target_size=(150, 150),
        batch_size=20,
        class_mode='binary')

history = model.fit_generator(
      train_generator,
      steps_per_epoch=100,
      epochs=30,
       validation_data=validation_generator)

# Accuracy on test data when trained with augmented training data
test_loss, test_accuracy = model.evaluate_generator(test_generator, steps=250) 
print(test_accuracy)

# plotting accuracy and loss graphs for training and validation
acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

# Taking pre-trained VGG16 model
conv_vgg16 = VGG16(weights = 'imagenet', include_top = False, input_shape = (150, 150, 3))

model = Sequential()
model.add(conv_vgg16)
model.add(layers.Flatten())
model.add(layers.Dense(256, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))

model.compile(
        loss='binary_crossentropy',
        optimizer=Adam(1e-4),
        metrics=['acc']
    )
 
model.summary()

history = model.fit_generator(
    train_generator,
    steps_per_epoch=100,
    epochs=100,
    validation_data=test_generator,
    validation_steps=10
)

#Saving the model 
model.save('vgg16.h5')

# Accuracy on test data when trained with augmented training data
test_loss, test_accuracy = model.evaluate_generator(test_generator, steps=50) 
print(test_accuracy)

# plotting accuracy and loss graphs for training and validation
acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()